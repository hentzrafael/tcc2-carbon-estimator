{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hentzrafael/tcc2-carbon-estimator/blob/main/carbon_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPxGRO3cmG0g"
      },
      "source": [
        "# Carbon estimation with Deep Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCBeg1z8mN1p"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jGlWFK4DVpU",
        "outputId": "d8884fe9-8dba-4639-90b3-4eec90cc72bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.10.5)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.0)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n",
            "Collecting mlflow-skinny==3.6.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.6.0 (from mlflow)\n",
            "  Downloading mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting Flask-CORS<7 (from mlflow)\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.1)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting huey<3,>=2.5.0 (from mlflow)\n",
            "  Downloading huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.44)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.2)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Downloading databricks_sdk-0.73.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.121.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (2.11.10)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.38.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (0.36.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (11.3.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (0.6.2)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (1.0.22)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (4.67.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.6.0->mlflow) (0.49.3)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.6.0->mlflow) (0.0.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.11)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8->segmentation_models_pytorch) (1.3.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.6.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (4.11.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.6.1)\n",
            "Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow-3.6.0-py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huey-2.5.4-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading databricks_sdk-0.73.0-py3-none-any.whl (753 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.9/753.9 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: huey, gunicorn, graphql-core, cligj, click-plugins, affine, rasterio, graphql-relay, docker, graphene, Flask-CORS, databricks-sdk, mlflow-tracing, mlflow-skinny, segmentation_models_pytorch, mlflow\n",
            "Successfully installed Flask-CORS-6.0.1 affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 databricks-sdk-0.73.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.5.4 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0 rasterio-1.4.3 segmentation_models_pytorch-0.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install rasterio mlflow tensorboard segmentation_models_pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwfskeG4mT-3"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mJdF97U2Dhvo"
      },
      "outputs": [],
      "source": [
        "input_file =  '/content/drive/MyDrive/TCC/data/reprojected.tif'\n",
        "target_file = '/content/drive/MyDrive/TCC/data/ceda2022Amazon.tif'\n",
        "patch_size = 1024\n",
        "stride = 128\n",
        "batch_size = 16\n",
        "epochs = 50\n",
        "SELECTED_MODEL = 'segformer'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QouUYqGSPVqM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import torchvision.utils as vutils\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import io\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import segmentation_models_pytorch as smp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVG8JebxmW-U"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GeoTiffPatchDatasetShuffled(Dataset):\n",
        "    _cached_inputs = None\n",
        "    _cached_targets = None\n",
        "    _cached_meta = None\n",
        "\n",
        "    def __init__(self, input_path, target_path, patch_size=256, stride=256,\n",
        "                 split=\"train\", seed=42, transform=None):\n",
        "        self.patch_size = patch_size\n",
        "        self.stride = stride\n",
        "        self.transform = transform\n",
        "        self.split = split\n",
        "        self.seed = seed\n",
        "\n",
        "        # Load or reuse\n",
        "        if GeoTiffPatchDatasetShuffled._cached_inputs is None:\n",
        "            with rasterio.open(input_path) as src_in:\n",
        "                GeoTiffPatchDatasetShuffled._cached_inputs = src_in.read().astype(np.float32)\n",
        "                GeoTiffPatchDatasetShuffled._cached_meta = (src_in.width, src_in.height, src_in.meta.copy())\n",
        "\n",
        "            with rasterio.open(target_path) as src_tgt:\n",
        "                GeoTiffPatchDatasetShuffled._cached_targets = src_tgt.read(1).astype(np.float32)\n",
        "\n",
        "        self.input_img = GeoTiffPatchDatasetShuffled._cached_inputs\n",
        "        self.target_img = GeoTiffPatchDatasetShuffled._cached_targets\n",
        "        self.width, self.height, self.input_meta = GeoTiffPatchDatasetShuffled._cached_meta\n",
        "\n",
        "        # Precompute only patch coordinates\n",
        "        coords = [\n",
        "            (left, top)\n",
        "            for top in range(0, self.height - patch_size + 1, stride)\n",
        "            for left in range(0, self.width - patch_size + 1, stride)\n",
        "        ]\n",
        "\n",
        "        # Shuffle and split\n",
        "        rng = np.random.default_rng(seed)\n",
        "        rng.shuffle(coords)\n",
        "        n_total = len(coords)\n",
        "        n_train = int(0.7 * n_total)\n",
        "        n_val = int(0.15 * n_total)\n",
        "        if split == \"train\":\n",
        "            self.coords = coords[:n_train]\n",
        "        elif split == \"val\":\n",
        "            self.coords = coords[n_train:n_train + n_val]\n",
        "        elif split == \"test\":\n",
        "            self.coords = coords[n_train + n_val:]\n",
        "        else:\n",
        "            self.coords = coords\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.coords)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        left, top = self.coords[idx]\n",
        "        ps = self.patch_size\n",
        "        input_patch = self.input_img[:, top:top+ps, left:left+ps]\n",
        "        target_patch = self.target_img[top:top+ps, left:left+ps]\n",
        "\n",
        "        is_valid = (~np.isnan(target_patch)) & (target_patch > 0)\n",
        "        mask = is_valid.astype(np.float32)\n",
        "\n",
        "        # # 2. Impute Invalid Values: Replace NaNs and all non-positive values with 0.\n",
        "        # #    This makes the data safe for log1p.\n",
        "        target_patch[~is_valid] = 0.0\n",
        "        # # Optional: Use np.nan_to_num(target_patch, nan=0.0) just to be absolutely sure.\n",
        "\n",
        "        # # 3. Apply the Safe Log Transformation\n",
        "        # # target_patch now contains only values >= 0, making log1p safe.\n",
        "        # target_patch = np.log1p(target_patch)\n",
        "\n",
        "        # Normalize inline\n",
        "        input_patch = input_patch.copy()\n",
        "\n",
        "        min_val = -3.0 # Assumindo que -3 é o pior outlier\n",
        "        max_val = 1.0\n",
        "\n",
        "        input_patch[3:] = (input_patch[3:] - min_val) / (max_val - min_val)\n",
        "        input_patch = np.clip(input_patch, 0.0, 1.0)\n",
        "\n",
        "\n",
        "        # # Mask\n",
        "        # mask = np.ones_like(target_patch, dtype=np.float32)\n",
        "        # target_patch = np.where(mask, target_patch, 0.0)\n",
        "\n",
        "\n",
        "        input_tensor = torch.from_numpy(input_patch)\n",
        "        target_tensor = torch.from_numpy(target_patch).float().unsqueeze(0)\n",
        "        mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            input_tensor, target_tensor, mask_tensor = self.transform(\n",
        "                input_tensor, target_tensor, mask_tensor\n",
        "            )\n",
        "\n",
        "        return input_tensor, target_tensor, mask_tensor, torch.tensor((left, top))\n"
      ],
      "metadata": {
        "id": "sSzhJaNt14y4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iFDvLLJmY_G"
      },
      "source": [
        "## Utils Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2knN_398C76_",
        "outputId": "f0102e36-c1cf-4b64-8bd8-12c4df1e05b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# -----------------------\n",
        "# Loss and training functions\n",
        "# -----------------------\n",
        "def masked_mse_loss(pred, target, mask):\n",
        "    # 1. Calcule a diferença (residual)\n",
        "    diff = (pred - target)\n",
        "\n",
        "    # 2. **CRITICAL: Eleve a diferença ao quadrado** (Erro Quadrático)\n",
        "    squared_error = diff * diff\n",
        "\n",
        "    # 3. Aplique a máscara ao erro quadrático\n",
        "    masked_squared_error = squared_error * mask\n",
        "\n",
        "    # 4. Garanta a divisão segura (para evitar NaN se o mask.sum() for 0)\n",
        "    denominator = torch.sum(mask)\n",
        "\n",
        "    # 5. Retorne a Média do Erro Quadrático\n",
        "    # Usamos torch.clamp para garantir que o denominador seja sempre >= 1e-8,\n",
        "    # prevenindo a divisão por zero.\n",
        "    return torch.sum(masked_squared_error) / torch.clamp(denominator, min=1e-8)\n",
        "\n",
        "\n",
        "def masked_smooth_l1_loss(pred, target, mask):\n",
        "    criterion = nn.SmoothL1Loss(reduction='none')\n",
        "    diff = criterion(pred, target)\n",
        "    return torch.sum(diff * mask) / torch.sum(mask)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def combined_structural_loss(pred, target, mask, lambda_grad=0.005):\n",
        "    \"\"\"\n",
        "    Calcula uma Loss Combinada: Smooth L1 Loss (Conteúdo) + Gradient Loss (Estrutura).\n",
        "\n",
        "    Parâmetros:\n",
        "        pred (Tensor): Predição do modelo (carbono).\n",
        "        target (Tensor): Alvo de carbono (Ground Truth).\n",
        "        mask (Tensor): Máscara de pixels válidos (1) e inválidos (0).\n",
        "        lambda_grad (float): Peso dado à Gradient Loss. Comece com 0.1 ou 0.05.\n",
        "\n",
        "    Retorna:\n",
        "        Tensor: O valor total da loss combinada.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. LOSS DE CONTEÚDO (Smooth L1) ---\n",
        "    content_criterion = nn.SmoothL1Loss(reduction='none')\n",
        "    content_loss_per_pixel = content_criterion(pred, target)\n",
        "\n",
        "    sum_content_loss = torch.sum(content_loss_per_pixel * mask)\n",
        "    denominator = torch.sum(mask)\n",
        "\n",
        "    # Garantia de divisão segura para evitar NaN\n",
        "    content_loss = sum_content_loss / torch.clamp(denominator, min=1e-8)\n",
        "\n",
        "    # ----------------------------------------------------\n",
        "    # --- 2. LOSS ESTRUTURAL (Gradient Loss - MSE sobre a Magnitude do Gradiente) ---\n",
        "\n",
        "    # Define os kernels Sobel (usados para encontrar bordas/gradientes)\n",
        "    sobel_x = torch.tensor([[[[-1., 0., 1.], [-2., 0., 2.], [-1., 0., 1.]]]],\n",
        "                           dtype=torch.float32,\n",
        "                           device=pred.device)\n",
        "    sobel_y = torch.tensor([[[[-1., -2., -1.], [0., 0., 0.], [1., 2., 1.]]]],\n",
        "                           dtype=torch.float32,\n",
        "                           device=pred.device)\n",
        "\n",
        "    # Calcula o gradiente em X e Y para a predição e o alvo\n",
        "    grad_x_pred = F.conv2d(pred, sobel_x, padding=1)\n",
        "    grad_y_pred = F.conv2d(pred, sobel_y, padding=1)\n",
        "\n",
        "    grad_x_target = F.conv2d(target, sobel_x, padding=1)\n",
        "    grad_y_target = F.conv2d(target, sobel_y, padding=1)\n",
        "\n",
        "    # Calcula a magnitude do gradiente (aproximação da intensidade da borda)\n",
        "    grad_pred_magnitude = torch.sqrt(grad_x_pred**2 + grad_y_pred**2)\n",
        "    grad_target_magnitude = torch.sqrt(grad_x_target**2 + grad_y_target**2)\n",
        "\n",
        "    # Calcula o Erro Quadrático Médio (MSE) entre as magnitudes dos gradientes\n",
        "    grad_diff = (grad_pred_magnitude - grad_target_magnitude)\n",
        "    grad_mse_per_pixel = grad_diff**2\n",
        "\n",
        "    # Aplica a máscara (o MSE entre gradientes deve ser minimizado apenas onde há dados válidos)\n",
        "    sum_grad_loss = torch.sum(grad_mse_per_pixel * mask)\n",
        "    gradient_loss = sum_grad_loss / torch.clamp(denominator, min=1e-8)\n",
        "\n",
        "    # --- 3. COMBINAÇÃO ---\n",
        "    total_loss = content_loss + lambda_grad * gradient_loss\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for inputs, targets, masks, _ in tqdm(loader):\n",
        "        inputs, targets, masks = inputs.to(device), targets.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = masked_smooth_l1_loss(outputs, targets, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * inputs.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "def validate_one_epoch(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets, masks, _ in tqdm(loader):\n",
        "            inputs, targets, masks = inputs.to(device), targets.to(device), masks.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = masked_smooth_l1_loss(outputs, targets, masks)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "\n",
        "def figure_to_array(fig):\n",
        "    \"\"\"Convert a matplotlib figure to a NumPy RGB array.\"\"\"\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
        "    buf.seek(0)\n",
        "    img = Image.open(buf).convert(\"RGB\")\n",
        "    return np.array(img)\n",
        "\n",
        "def visualize_sample(inputs, targets, preds, step, max_samples=3):\n",
        "    \"\"\"Save sample patches (input RGB, target, prediction)\"\"\"\n",
        "    os.makedirs(\"samples\", exist_ok=True)\n",
        "    samples_logged = 0\n",
        "\n",
        "    for i in range(min(max_samples, inputs.size(0))):\n",
        "        inp = inputs[i, :3].cpu().numpy().transpose(1, 2, 0)  # RGB bands\n",
        "        inp = (inp - inp.min()) / (inp.max() - inp.min() + 1e-8)\n",
        "        tgt = targets[i, 0].cpu().numpy()\n",
        "        pred = preds[i, 0].cpu().numpy()\n",
        "\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(9, 3))\n",
        "        axs[0].imshow(inp)\n",
        "        axs[0].set_title(\"Input RGB\")\n",
        "        axs[1].imshow(tgt, cmap=\"viridis\")\n",
        "        axs[1].set_title(\"Target\")\n",
        "        axs[2].imshow(pred, cmap=\"viridis\")\n",
        "        axs[2].set_title(\"Prediction\")\n",
        "        for ax in axs: ax.axis(\"off\")\n",
        "\n",
        "        fig.tight_layout()\n",
        "        path = f\"samples/sample_{step}_idx{i}.png\"\n",
        "        plt.savefig(path)\n",
        "        plt.close(fig)\n",
        "\n",
        "        img_array = figure_to_array(fig)\n",
        "        # Log image to TensorBoard\n",
        "        writer.add_image(f\"Samples/Epoch_{step}_Sample_{i}\", img_array.transpose(2, 0, 1), global_step=step)\n",
        "\n",
        "        # Also store the sample in MLflow\n",
        "        mlflow.log_image(Image.fromarray(img_array), f\"samples/Epoch_{step}.png\")\n",
        "        samples_logged += 1\n",
        "\n",
        "    print(f\"Logged {samples_logged} sample images for epoch {step}\")\n",
        "\n",
        "def log_alignment_check(dataset, writer=None, step=0, mlflow_log=True):\n",
        "    \"\"\"\n",
        "    Logs an overlay of input RGB and target mask to TensorBoard and MLflow.\n",
        "    Helps visually check if patches are spatially aligned.\n",
        "    \"\"\"\n",
        "    idx = np.random.randint(0, len(dataset))\n",
        "    input_patch, target_patch, _, __ = dataset[idx]\n",
        "\n",
        "    # Convert tensors if necessary\n",
        "    if torch.is_tensor(input_patch):\n",
        "        input_patch = input_patch.cpu().numpy()\n",
        "    if torch.is_tensor(target_patch):\n",
        "        target_patch = target_patch.cpu().numpy()\n",
        "\n",
        "    # Prepare RGB (only first 3 bands)\n",
        "    rgb = np.clip(input_patch[:3].transpose(1, 2, 0), 0, 1)\n",
        "\n",
        "    # Handle single-channel target (1, H, W) or (H, W)\n",
        "    if target_patch.ndim == 3 and target_patch.shape[0] == 1:\n",
        "        target_patch = target_patch[0]\n",
        "    elif target_patch.ndim == 3:\n",
        "        target_patch = target_patch[0]\n",
        "\n",
        "    # Normalize target for visualization\n",
        "    tgt_norm = (target_patch - np.nanmin(target_patch)) / (np.nanmax(target_patch) - np.nanmin(target_patch) + 1e-8)\n",
        "\n",
        "    # Create figure\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    ax[0].imshow(rgb)\n",
        "    ax[0].set_title(\"Input RGB\")\n",
        "    ax[1].imshow(tgt_norm, cmap=\"viridis\")\n",
        "    ax[1].set_title(\"Target\")\n",
        "    ax[2].imshow(rgb)\n",
        "    ax[2].imshow(tgt_norm, cmap=\"viridis\", alpha=0.4)\n",
        "    ax[2].set_title(\"Overlay\")\n",
        "    for a in ax:\n",
        "        a.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Log to TensorBoard\n",
        "    if writer:\n",
        "        writer.add_figure(\"Alignment_Check\", fig, global_step=step)\n",
        "\n",
        "    # Log to MLflow\n",
        "    if mlflow_log:\n",
        "        import mlflow\n",
        "        buf = io.BytesIO()\n",
        "        fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
        "        buf.seek(0)\n",
        "        pil_img = Image.open(buf)\n",
        "        mlflow.log_image(pil_img, artifact_file=\"alignment_check.png\")\n",
        "\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Main\n",
        "# -----------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krqxj8ZSmds1"
      },
      "source": [
        "## Model definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344,
          "referenced_widgets": [
            "65c7702375f147b0829b5152b39a50eb",
            "dec973c293b64206bdddc07003bb6a13",
            "7c24b78d2f31486aa54c69aeecb2501f",
            "1e14b12e8aeb4a19b014641c05d831db",
            "c05975afb8e548e7a53998373d1b93a0",
            "e1a3a1f404bb46528276217de29eaf6c",
            "a7548fa924744082990a95bf36deb489",
            "4292ecf2129c4b569b8886f880694261",
            "ae8d4b0055f54412a5c95334cd7e92ff",
            "f3ed7074f3cd434885ae68aa140e08db",
            "836caa64d68c4e7bbc7a328cea9c9774",
            "e275fced82bd4d85aa28b768129ae6a8",
            "2478903493cc4ff1ab250d8798c0b359",
            "e2339ac5b53a40bdbe941ecc82f9bd68",
            "310efca7cf514bb79f3ba903b344341e",
            "01f60e9c968c4320ba3598580320e5c3",
            "274ff308437d45b4a99430542531e90e",
            "5b2e4f2048f54bb0976cd75c04a7c13e",
            "f47bfd924a614052ad7396d3a0b069fa",
            "2b614776a4364a58938e554b93924f21",
            "ac1e3787f47b475e9c677981d2bf3501",
            "50e9dac892e54a589d23ca2b9b7953d0",
            "909c6091b2654de586f51af3c4bf224d",
            "69a6020dc6e449ad9af4e8b420cc5dbf",
            "3752ea375fb548b1a21015e9fe11884c",
            "95337d11d6a44ee98c4d30e513515ab9",
            "808c4dea4a50481aaff31c805daf56e3",
            "f7bb805f537749809abc131291b259cf",
            "a1898faf02a849469f2977aebd0119e0",
            "aad64cae9e56494ea604153af3b60c48",
            "87a2117760314431a2abdc3bea886a67",
            "a6b81835d5b24b6bada013539ebdccde",
            "a51aa5a67b77486fb78cdda2ec8f1ed7",
            "9ca37000ea774d36b622dda912f52942",
            "9907d31bb5b24c67ba52f6a0bf74c422",
            "edbfcac2a7f74fa7b653be98fcef3964",
            "8d4c2390f1af44158d2162a7ea3b19e2",
            "e5fdd311ebaa4c20a146997ddaa6275c",
            "66ff676323fb4263a2fc6d9756bd31db",
            "ada2f4cea11546c4839f9bbb0ee2887c",
            "d85fcfdd78dc40e882df2aabdb3c0368",
            "e568108819504db0a83c06c0ed6ece95",
            "41a8d0b9372649079cd1ab6cccb55c81",
            "13353bb2e2154bce88846bd8ac6565fb",
            "f0fd5dec088544acb523cabba8a1aadd",
            "4e6243c147974d398a0e70e1fdb4de98",
            "dfc3da0ffbb4449bbcf57f04c9850827",
            "2c8034c21639465b9c2a3bc7674c79c3",
            "b38de8d85a7042619f02c12ae70c5a89",
            "034e17a25365420f80cb10f05def8102",
            "8c9c2c9b35e447a49af97a68c9696d54",
            "6990c82ee06d44cda4b48a0b35cb23fa",
            "05383cebc52442e1a8f9ae691000c079",
            "381474ca5582498ea959b60a8d2fec21",
            "6fdb8308de0342ae9f77c5816a7694e2"
          ]
        },
        "id": "quu8xdHlj4TD",
        "outputId": "9e726af5-41da-4ff7-d1d9-06f074082cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65c7702375f147b0829b5152b39a50eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e275fced82bd4d85aa28b768129ae6a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/850M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "909c6091b2654de586f51af3c4bf224d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/decoders/dpt/model.py:118: UserWarning: Encoder does not have prefix tokens (e.g. cls_token), but `decoder_readout` is set to 'cat'. It's recommended to set `decoder_readout='ignore'` when using a encoder without prefix tokens.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ca37000ea774d36b622dda912f52942"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0fd5dec088544acb523cabba8a1aadd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "MODELS = {\n",
        "    'unetplus': smp.UnetPlusPlus(\n",
        "      encoder_name=\"resnet152\",        # backbone\n",
        "      encoder_weights=\"imagenet\",            # set to \"imagenet\" if you want pretrained weights\n",
        "      in_channels=5,                   # your dataset has 5 input channels\n",
        "      classes=1,\n",
        "    ),\n",
        "    'dpt': smp.DPT(\n",
        "        encoder_name='tu-maxvit_large_tf_512.in21k_ft_in1k',\n",
        "        in_channels=5,\n",
        "        classes=1,\n",
        "    ),\n",
        "    'segformer': smp.Segformer(\n",
        "        encoder_name=\"mit_b5\",\n",
        "        encoder_weights=\"imagenet\",\n",
        "        in_channels=5,\n",
        "        classes=1,\n",
        "    ),\n",
        "    'unet': smp.Unet(\n",
        "      encoder_name=\"resnet152\",        # backbone\n",
        "      encoder_weights=\"imagenet\",            # set to \"imagenet\" if you want pretrained weights\n",
        "      in_channels=5,                   # your dataset has 5 input channels\n",
        "      classes=1,\n",
        "    ),\n",
        "}\n",
        "model = MODELS[SELECTED_MODEL] # Change this to control which model to use\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kGV4mMymqiV"
      },
      "source": [
        "## Dataset loading in memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4_PEg-lYIXIx"
      },
      "outputs": [],
      "source": [
        "# Dataset and loader\n",
        "train_dataset = GeoTiffPatchDatasetShuffled(input_file, target_file, split='train')\n",
        "val_dataset = GeoTiffPatchDatasetShuffled(input_file, target_file, split='val')\n",
        "test_dataset = GeoTiffPatchDatasetShuffled(input_file, target_file, split='test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZasZyHC0m1jb"
      },
      "source": [
        "## Experiment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I9gQ6fmhJIfA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc4db41-3e18-44a8-f19a-ee039fe9daf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
            "  return FileStore(store_uri, store_uri)\n",
            "2025/11/15 03:21:42 INFO mlflow.tracking.fluent: Experiment with name 'Carbon_Tracking' does not exist. Creating a new experiment.\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "# --- Setup experiment tracking ---\n",
        "experiment_name = \"Carbon_Tracking\"\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "run_name = f\"carbon_run_{SELECTED_MODEL}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "log_dir = os.path.join(\"/content/drive/MyDrive/TCC/runs\", run_name)\n",
        "writer = SummaryWriter(log_dir=log_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxHHxl4xOXlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a30b7a6-1293-48b7-bca2-0fcd51265579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 560/560 [03:34<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 221.090565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:16<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 216.618419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/11/15 03:25:49 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: RuntimeError('Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor'). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n",
            "2025/11/15 03:25:49 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2025/11/15 03:26:26 WARNING mlflow.models.model: Failed to validate serving input example {\n",
            "  \"inputs\": [\n",
            "    [\n",
            "      [\n",
            "        [\n",
            "          .... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
            "Got error: Input type (double) and bias type (float) should be the same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model: val_loss=216.618419\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 560/560 [03:29<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 208.063626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:15<00:00,  7.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 202.643257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/11/15 03:30:22 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: RuntimeError('Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor'). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n",
            "2025/11/15 03:30:23 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2025/11/15 03:30:54 WARNING mlflow.models.model: Failed to validate serving input example {\n",
            "  \"inputs\": [\n",
            "    [\n",
            "      [\n",
            "        [\n",
            "          .... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
            "Got error: Input type (double) and bias type (float) should be the same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model: val_loss=202.643257\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 560/560 [03:28<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 192.837313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:15<00:00,  7.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 189.601349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/11/15 03:34:50 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: RuntimeError('Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor'). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n",
            "2025/11/15 03:34:51 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2025/11/15 03:35:21 WARNING mlflow.models.model: Failed to validate serving input example {\n",
            "  \"inputs\": [\n",
            "    [\n",
            "      [\n",
            "        [\n",
            "          .... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
            "Got error: Input type (double) and bias type (float) should be the same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model: val_loss=189.601349\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 5/560 [00:02<03:49,  2.42it/s]"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run(run_name=run_name):\n",
        "    mlflow.log_param(\"patch_size\", patch_size)\n",
        "    mlflow.log_param(\"stride\", stride)\n",
        "    mlflow.log_param(\"batch_size\", batch_size)\n",
        "    mlflow.log_param(\"epochs\", epochs)\n",
        "    mlflow.log_param(\"learning_rate\", 1e-4)\n",
        "    log_alignment_check(train_dataset, writer, step=0, mlflow_log=True)\n",
        "    # mlflow.log_param(\"model\", \"UNet_5_to_1\")\n",
        "\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "\n",
        "    mlflow.log_param(\"model\", SELECTED_MODEL)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"Epoch {epoch}/{epochs}\")\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
        "        print(f\"Train Loss: {train_loss:.6f}\")\n",
        "\n",
        "        val_loss = validate_one_epoch(model, val_loader, device)\n",
        "        print(f\"Validation Loss: {val_loss:.6f}\")\n",
        "\n",
        "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
        "        writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
        "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
        "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
        "\n",
        "        if epoch % 5 == 0 or epoch == epochs:  # every 5 epochs or last\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_inputs, val_targets, val_masks, _ = next(iter(val_loader))\n",
        "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
        "                preds = model(val_inputs)\n",
        "                visualize_sample(val_inputs, val_targets, preds, epoch)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_path = f\"/content/drive/MyDrive/TCC/{SELECTED_MODEL}.pt\"\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            example = torch.randn(1, 5, patch_size, patch_size).cpu().numpy()\n",
        "            mlflow.pytorch.log_model(model, name=\"model\",input_example=example)\n",
        "            mlflow.log_artifact(best_model_path)\n",
        "            print(f\"✅ Saved new best model: val_loss={best_val_loss:.6f}\")\n",
        "\n",
        "    mlflow.log_metric(\"best_val_loss\", best_val_loss)\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    print(f\"Best validation loss: {best_val_loss:.6f}\")\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import mlflow\n",
        "\n",
        "def evaluate_model(model, test_loader, device, writer=None, step=None):\n",
        "    \"\"\"\n",
        "    Evaluate a trained model on the test dataset, logging metrics to TensorBoard and MLflow.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    preds, targets, masks = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs = batch[0].to(device, non_blocking=True)\n",
        "            y_true = batch[1].to(device, non_blocking=True)\n",
        "            mask_batch = batch[2].to(device, non_blocking=True)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            preds.append(outputs.detach().cpu().numpy())\n",
        "            targets.append(y_true.detach().cpu().numpy())\n",
        "            masks.append(mask_batch.detach().cpu().numpy())\n",
        "\n",
        "    # Stack all predictions and targets\n",
        "    preds = np.concatenate(preds, axis=0).flatten()\n",
        "    targets = np.concatenate(targets, axis=0).flatten()\n",
        "    masks = np.concatenate(masks, axis=0).flatten()\n",
        "\n",
        "    valid_indices = masks == 1\n",
        "    preds_valid = preds[valid_indices]\n",
        "    targets_valid = targets[valid_indices]\n",
        "\n",
        "    # Compute metrics\n",
        "    # targets_valid = np.expm1(targets_valid)\n",
        "    # preds_valid = np.expm1(preds_valid)\n",
        "\n",
        "    mse = mean_squared_error(targets_valid, preds_valid)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(targets_valid, preds_valid)\n",
        "    r2 = r2_score(targets_valid, preds_valid)\n",
        "\n",
        "    # Log metrics\n",
        "    print(f\"\\n--- Test Metrics ---\")\n",
        "    print(f\"RMSE: {rmse:.6f}\")\n",
        "    print(f\"MAE : {mae:.6f}\")\n",
        "    print(f\"R²  : {r2:.6f}\")\n",
        "\n",
        "    # ✅ TensorBoard logging\n",
        "    if writer is not None:\n",
        "        writer.add_scalar('Test/RMSE', rmse, step or 0)\n",
        "        writer.add_scalar('Test/MAE', mae, step or 0)\n",
        "        writer.add_scalar('Test/R2', r2, step or 0)\n",
        "        writer.flush()\n",
        "\n",
        "    # ✅ MLflow logging\n",
        "    mlflow.log_metric(\"test_rmse\", rmse)\n",
        "    mlflow.log_metric(\"test_mae\", mae)\n",
        "    mlflow.log_metric(\"test_r2\", r2)\n",
        "\n",
        "    return rmse, mae, r2\n",
        "\n",
        "rmse, mae, r2 = evaluate_model(model, test_loader, device, writer)\n",
        "print(\"Evaluation completed.\")\n"
      ],
      "metadata": {
        "id": "n2Qm2auCPfqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "yrst_zoSnMp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Trainable parameters: {trainable_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzbrmX_sJ8MI",
        "outputId": "6efa834b-33e3-46eb-c679-190265306cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 67163153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ067IoKlbnf"
      },
      "outputs": [],
      "source": [
        "def predict_geotiff(model, input_file, target_file, output_file, patch_size, stride, batch_size, device, run_name=\"EvaluationRun\"):\n",
        "    # --- Start MLflow run ---\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        mlflow.log_param(\"patch_size\", patch_size)\n",
        "        mlflow.log_param(\"stride\", stride)\n",
        "        mlflow.log_param(\"batch_size\", batch_size)\n",
        "        mlflow.log_param(\"model_checkpoint\", os.path.basename(output_file))\n",
        "\n",
        "        # Create dataset for inference (no train/val split needed)\n",
        "        inference_dataset = GeoTiffPatchDatasetShuffled(\n",
        "            input_file, target_file,\n",
        "            patch_size=patch_size, stride=stride, split='all' # Use split='all' for inference\n",
        "        )\n",
        "        inference_loader = DataLoader(inference_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "        # Prepare output array\n",
        "        output_arr = np.zeros((inference_dataset.height, inference_dataset.width), dtype=np.float32)\n",
        "        count_arr = np.zeros((inference_dataset.height, inference_dataset.width), dtype=np.int32) # To handle overlaps\n",
        "\n",
        "        model.eval()\n",
        "        mae_list, rmse_list = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets, masks, coords in tqdm(inference_loader, desc=\"Predicting patches\"):\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                preds = model(inputs)\n",
        "\n",
        "                outputs_np = preds.squeeze(1).cpu().numpy()\n",
        "                targets_np = targets.squeeze(1).cpu().numpy()\n",
        "\n",
        "                # Compute metrics for this batch\n",
        "                # Apply mask before computing metrics\n",
        "                masked_outputs = outputs_np * masks.squeeze(1).cpu().numpy()\n",
        "                masked_targets = targets_np * masks.squeeze(1).cpu().numpy()\n",
        "\n",
        "                mae = np.sum(np.abs(masked_outputs - masked_targets)) / np.sum(masks.cpu().numpy())\n",
        "                rmse = np.sqrt(np.sum((masked_outputs - masked_targets) ** 2) / np.sum(masks.cpu().numpy()))\n",
        "\n",
        "                mae_list.append(mae)\n",
        "                rmse_list.append(rmse)\n",
        "\n",
        "\n",
        "                # Merge patch predictions into the mosaic\n",
        "                for i in range(outputs_np.shape[0]):\n",
        "                    left, top = coords[i][0].item(), coords[i][1].item()\n",
        "                    output_arr[top : top + patch_size, left : left + patch_size] += outputs_np[i]\n",
        "                    count_arr[top : top + patch_size, left : left + patch_size] += 1\n",
        "\n",
        "        # Final averaged map\n",
        "        output_arr /= np.maximum(count_arr, 1)\n",
        "\n",
        "        # --- Compute global metrics ---\n",
        "        mae_global = float(np.mean(mae_list))\n",
        "        rmse_global = float(np.mean(rmse_list))\n",
        "        mlflow.log_metric(\"MAE\", mae_global)\n",
        "        mlflow.log_metric(\"RMSE\", rmse_global)\n",
        "\n",
        "        print(f\"✅ MAE: {mae_global:.4f}, RMSE: {rmse_global:.4f}\")\n",
        "\n",
        "        # --- Save predicted GeoTIFF ---\n",
        "        output_meta = inference_dataset.input_meta.copy()\n",
        "        output_meta.update({'count': 1, 'dtype': 'float32'})\n",
        "\n",
        "        with rasterio.open(output_file, 'w', **output_meta) as dst:\n",
        "            dst.write(output_arr, 1)\n",
        "\n",
        "        print(f\"Prediction saved to {output_file}\")\n",
        "        mlflow.log_artifact(output_file)\n",
        "\n",
        "        # --- Visualization ---\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        sample_idx = 0\n",
        "        rgb = inputs[sample_idx, :3].cpu().numpy().transpose(1, 2, 0)\n",
        "        tgt = targets[sample_idx, 0].cpu().numpy()\n",
        "        pred = preds[sample_idx, 0].cpu().numpy()\n",
        "\n",
        "        axes[0].imshow(rgb)\n",
        "        axes[0].set_title(\"Input RGB\")\n",
        "        axes[1].imshow(tgt, cmap='viridis')\n",
        "        axes[1].set_title(\"Target\")\n",
        "        axes[2].imshow(pred, cmap='viridis')\n",
        "        axes[2].set_title(\"Prediction\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        fig_path = \"evaluation_sample.png\"\n",
        "        plt.savefig(fig_path, dpi=300)\n",
        "        mlflow.log_artifact(fig_path)\n",
        "        plt.close(fig)\n",
        "\n",
        "        print(\"🧾 Evaluation artifacts logged to MLflow.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aabac7cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67f96f4-5740-422d-9ac2-31594931c3a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Model loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting patches:   3%|▎         | 174/6243 [02:33<1:25:26,  1.18it/s]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Main prediction function\n",
        "# def predict_geotiff(model, input_file, target_file, output_file, patch_size, stride, batch_size, device, name):\n",
        "#     # Create dataset for inference (no train/val split needed)\n",
        "#     inference_dataset = GeoTiffPatchDatasetShuffled(input_file, target_file, patch_size=patch_size, stride=stride, split='all')\n",
        "#     inference_loader = DataLoader(inference_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "#     # Prepare output array\n",
        "#     output_arr = np.zeros((inference_dataset.height, inference_dataset.width), dtype=np.float32)\n",
        "#     count_arr = np.zeros((inference_dataset.height, inference_dataset.width), dtype=np.int32) # To handle overlaps\n",
        "\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, targets, masks, coords in tqdm(inference_loader, desc=\"Predicting patches\"):\n",
        "#             inputs = inputs.to(device)\n",
        "#             outputs = model(inputs)\n",
        "\n",
        "#             # Move predictions to CPU and convert to numpy\n",
        "#             outputs_np = outputs.squeeze(1).cpu().numpy() # Remove channel dimension\n",
        "\n",
        "#             # Place predictions into the output array\n",
        "#             for i in range(outputs_np.shape[0]):\n",
        "#                 left, top = coords[0][i], coords[1][i] # Access coordinates correctly\n",
        "#                 output_arr[top : top + patch_size, left : left + patch_size] += outputs_np[i]\n",
        "#                 count_arr[top : top + patch_size, left : left + patch_size] += 1\n",
        "\n",
        "#     # Average overlapping predictions\n",
        "#     output_arr /= np.maximum(count_arr, 1) # Avoid division by zero\n",
        "\n",
        "#     # Save the output GeoTIFF\n",
        "#     output_meta = inference_dataset.input_meta.copy()\n",
        "#     output_meta.update({\n",
        "#         'count': 1,  # Single band output\n",
        "#         'dtype': 'float32'\n",
        "#     })\n",
        "\n",
        "#     with rasterio.open(output_file, 'w', **output_meta) as dst:\n",
        "#         dst.write(output_arr, 1)\n",
        "\n",
        "#     print(f\"Prediction saved to {output_file}\")\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load the trained model\n",
        "    # model = smp.DeepLabV3Plus(\n",
        "    #   encoder_name=\"resnet101\",        # backbone\n",
        "    #   encoder_weights=\"imagenet\",            # set to \"imagenet\" if you want pretrained weights\n",
        "    #   in_channels=5,                   # your dataset has 5 input channels\n",
        "    #   classes=1,                       # single regression/segmentation output\n",
        "    # )\n",
        "    # model = model.to(device)\n",
        "    model.load_state_dict(torch.load(f'/content/drive/MyDrive/TCC/{SELECTED_MODEL}.pt'))\n",
        "    print(\"Model loaded successfully.\")\n",
        "\n",
        "    input_file =  '/content/drive/MyDrive/TCC/data/input2021.tif'\n",
        "\n",
        "    # Define output file path\n",
        "    output_file = f'/content/drive/MyDrive/TCC/data/amazonPrediction2021{SELECTED_MODEL}.tif'\n",
        "\n",
        "    # Run prediction\n",
        "    predict_geotiff(model, input_file, target_file, output_file, patch_size, stride, batch_size, device,'Biomass_Prediction_Evaluation')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ./mlruns/* /content/drive/MyDrive/TCC/mlruns/segformer"
      ],
      "metadata": {
        "id": "V9onAq6r7GXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1AEPPIEtqTWoktZ7AaVBZoEnY7EOXWjKP",
      "authorship_tag": "ABX9TyOxtGPBZUPgC8zQ+HxVp4v0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65c7702375f147b0829b5152b39a50eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dec973c293b64206bdddc07003bb6a13",
              "IPY_MODEL_7c24b78d2f31486aa54c69aeecb2501f",
              "IPY_MODEL_1e14b12e8aeb4a19b014641c05d831db"
            ],
            "layout": "IPY_MODEL_c05975afb8e548e7a53998373d1b93a0"
          }
        },
        "dec973c293b64206bdddc07003bb6a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a3a1f404bb46528276217de29eaf6c",
            "placeholder": "​",
            "style": "IPY_MODEL_a7548fa924744082990a95bf36deb489",
            "value": "config.json: 100%"
          }
        },
        "7c24b78d2f31486aa54c69aeecb2501f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4292ecf2129c4b569b8886f880694261",
            "max": 156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae8d4b0055f54412a5c95334cd7e92ff",
            "value": 156
          }
        },
        "1e14b12e8aeb4a19b014641c05d831db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3ed7074f3cd434885ae68aa140e08db",
            "placeholder": "​",
            "style": "IPY_MODEL_836caa64d68c4e7bbc7a328cea9c9774",
            "value": " 156/156 [00:00&lt;00:00, 18.6kB/s]"
          }
        },
        "c05975afb8e548e7a53998373d1b93a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a3a1f404bb46528276217de29eaf6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7548fa924744082990a95bf36deb489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4292ecf2129c4b569b8886f880694261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae8d4b0055f54412a5c95334cd7e92ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3ed7074f3cd434885ae68aa140e08db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "836caa64d68c4e7bbc7a328cea9c9774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e275fced82bd4d85aa28b768129ae6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2478903493cc4ff1ab250d8798c0b359",
              "IPY_MODEL_e2339ac5b53a40bdbe941ecc82f9bd68",
              "IPY_MODEL_310efca7cf514bb79f3ba903b344341e"
            ],
            "layout": "IPY_MODEL_01f60e9c968c4320ba3598580320e5c3"
          }
        },
        "2478903493cc4ff1ab250d8798c0b359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_274ff308437d45b4a99430542531e90e",
            "placeholder": "​",
            "style": "IPY_MODEL_5b2e4f2048f54bb0976cd75c04a7c13e",
            "value": "model.safetensors: 100%"
          }
        },
        "e2339ac5b53a40bdbe941ecc82f9bd68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f47bfd924a614052ad7396d3a0b069fa",
            "max": 241448640,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b614776a4364a58938e554b93924f21",
            "value": 241448640
          }
        },
        "310efca7cf514bb79f3ba903b344341e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac1e3787f47b475e9c677981d2bf3501",
            "placeholder": "​",
            "style": "IPY_MODEL_50e9dac892e54a589d23ca2b9b7953d0",
            "value": " 241M/241M [00:02&lt;00:00, 107MB/s]"
          }
        },
        "01f60e9c968c4320ba3598580320e5c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "274ff308437d45b4a99430542531e90e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b2e4f2048f54bb0976cd75c04a7c13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f47bfd924a614052ad7396d3a0b069fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b614776a4364a58938e554b93924f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac1e3787f47b475e9c677981d2bf3501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e9dac892e54a589d23ca2b9b7953d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "909c6091b2654de586f51af3c4bf224d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69a6020dc6e449ad9af4e8b420cc5dbf",
              "IPY_MODEL_3752ea375fb548b1a21015e9fe11884c",
              "IPY_MODEL_95337d11d6a44ee98c4d30e513515ab9"
            ],
            "layout": "IPY_MODEL_808c4dea4a50481aaff31c805daf56e3"
          }
        },
        "69a6020dc6e449ad9af4e8b420cc5dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7bb805f537749809abc131291b259cf",
            "placeholder": "​",
            "style": "IPY_MODEL_a1898faf02a849469f2977aebd0119e0",
            "value": "model.safetensors: 100%"
          }
        },
        "3752ea375fb548b1a21015e9fe11884c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aad64cae9e56494ea604153af3b60c48",
            "max": 850242572,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87a2117760314431a2abdc3bea886a67",
            "value": 850242572
          }
        },
        "95337d11d6a44ee98c4d30e513515ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b81835d5b24b6bada013539ebdccde",
            "placeholder": "​",
            "style": "IPY_MODEL_a51aa5a67b77486fb78cdda2ec8f1ed7",
            "value": " 850M/850M [00:02&lt;00:00, 578MB/s]"
          }
        },
        "808c4dea4a50481aaff31c805daf56e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7bb805f537749809abc131291b259cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1898faf02a849469f2977aebd0119e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aad64cae9e56494ea604153af3b60c48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a2117760314431a2abdc3bea886a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6b81835d5b24b6bada013539ebdccde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51aa5a67b77486fb78cdda2ec8f1ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ca37000ea774d36b622dda912f52942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9907d31bb5b24c67ba52f6a0bf74c422",
              "IPY_MODEL_edbfcac2a7f74fa7b653be98fcef3964",
              "IPY_MODEL_8d4c2390f1af44158d2162a7ea3b19e2"
            ],
            "layout": "IPY_MODEL_e5fdd311ebaa4c20a146997ddaa6275c"
          }
        },
        "9907d31bb5b24c67ba52f6a0bf74c422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66ff676323fb4263a2fc6d9756bd31db",
            "placeholder": "​",
            "style": "IPY_MODEL_ada2f4cea11546c4839f9bbb0ee2887c",
            "value": "config.json: 100%"
          }
        },
        "edbfcac2a7f74fa7b653be98fcef3964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d85fcfdd78dc40e882df2aabdb3c0368",
            "max": 135,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e568108819504db0a83c06c0ed6ece95",
            "value": 135
          }
        },
        "8d4c2390f1af44158d2162a7ea3b19e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41a8d0b9372649079cd1ab6cccb55c81",
            "placeholder": "​",
            "style": "IPY_MODEL_13353bb2e2154bce88846bd8ac6565fb",
            "value": " 135/135 [00:00&lt;00:00, 18.7kB/s]"
          }
        },
        "e5fdd311ebaa4c20a146997ddaa6275c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66ff676323fb4263a2fc6d9756bd31db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ada2f4cea11546c4839f9bbb0ee2887c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d85fcfdd78dc40e882df2aabdb3c0368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e568108819504db0a83c06c0ed6ece95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41a8d0b9372649079cd1ab6cccb55c81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13353bb2e2154bce88846bd8ac6565fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0fd5dec088544acb523cabba8a1aadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e6243c147974d398a0e70e1fdb4de98",
              "IPY_MODEL_dfc3da0ffbb4449bbcf57f04c9850827",
              "IPY_MODEL_2c8034c21639465b9c2a3bc7674c79c3"
            ],
            "layout": "IPY_MODEL_b38de8d85a7042619f02c12ae70c5a89"
          }
        },
        "4e6243c147974d398a0e70e1fdb4de98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_034e17a25365420f80cb10f05def8102",
            "placeholder": "​",
            "style": "IPY_MODEL_8c9c2c9b35e447a49af97a68c9696d54",
            "value": "model.safetensors: 100%"
          }
        },
        "dfc3da0ffbb4449bbcf57f04c9850827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6990c82ee06d44cda4b48a0b35cb23fa",
            "max": 327923200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05383cebc52442e1a8f9ae691000c079",
            "value": 327923200
          }
        },
        "2c8034c21639465b9c2a3bc7674c79c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_381474ca5582498ea959b60a8d2fec21",
            "placeholder": "​",
            "style": "IPY_MODEL_6fdb8308de0342ae9f77c5816a7694e2",
            "value": " 328M/328M [00:04&lt;00:00, 118MB/s]"
          }
        },
        "b38de8d85a7042619f02c12ae70c5a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "034e17a25365420f80cb10f05def8102": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c9c2c9b35e447a49af97a68c9696d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6990c82ee06d44cda4b48a0b35cb23fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05383cebc52442e1a8f9ae691000c079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "381474ca5582498ea959b60a8d2fec21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fdb8308de0342ae9f77c5816a7694e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}